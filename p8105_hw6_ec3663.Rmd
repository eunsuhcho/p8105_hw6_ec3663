---
title: "Homework 6"
author: "Eunsuh Cho"
output: github_document
---

```{r}
library(tidyverse)
library(modelr)
library(mgcv)
library(dplyr)
library(knitr)

set.seed(1)
```

# Problem 1

# Problem 2

Downloading data

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

Creating 5000 bootstrap samples

```{r}
bootstrap_df = weather_df |> 
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map(models, broom::tidy),
    rsq = map(models, broom::glance)) |> 
  select(results, .id, rsq) |> 
  unnest(results) |> 
  filter(term %in% c("tmin", "prcp")) |> 
  group_by(.id) |> 
  mutate(beta1xbeta2 = prod(estimate),
         log_beta_product = log(beta1xbeta2)) |> 
  select(log_beta_product, rsq) |> 
  unnest(rsq) |> 
  janitor::clean_names() |> 
  select(log_beta_product, id, r_squared) |> 
  unique()
```

Plotting distribution of estimates

Log of the beta product
```{r}
bootstrap_df |> 
  ggplot(aes(x = log_beta_product)) + geom_density()
```
The figure above displays the distribution of the estimates of the log of the product of betas 1 and 2. The distribution is left skewed and unimodal with a peak at approximately -5.75.

R-squared
```{r}
bootstrap_df |> 
  ggplot(aes(x = r_squared)) + geom_density()
```
The figure above displays the distribution of the estimates of the r-squared value. The distribution is almost normal (slightly left skewed) and unimodal with a peak at approximately 0.916.

Providing a 95% confidence interval

```{r}
bootstrap_conf = bootstrap_df |> 
  unique() |>
  ungroup() |> 
  select(-id) |> 
  summarize(beta_mean = mean(log_beta_product, na.rm = TRUE),
            beta_low = quantile(log_beta_product, 0.025, na.rm = TRUE),
            beta_high = quantile(log_beta_product, 0.975, na.rm = TRUE),
            rs_mean = mean(r_squared),
            rs_low = quantile(r_squared, 0.025),
            rs_high = quantile(r_squared, 0.975))

bootstrap_conf |> knitr::kable()
```

The 95% confidence interval for the log of the beta product is (`r bootstrap_conf$beta_low`, `r bootstrap_conf$beta_high`).

The 95% confidence interval for r-squared is (`r bootstrap_conf$rs_low`, `r bootstrap_conf$rs_high`).

# Problem 3

Downloading data

```{r}
bw_df = read.csv("birthweight.csv")

bw_df = bw_df |> 
  janitor::clean_names() |> 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)) |> 
  drop_na()
```

Proposing a regression model

```{r}
fit = lm(bwt ~ delwt + gaweeks + smoken + wtgain, data = bw_df)

fit |>
  broom::tidy() |>
  select(term, estimate, p.value) |>
  knitr::kable(digits=3)

summary(fit)
```

The proposed model is based on biological factors that have been proven to have an effect on the baby's weight, including `delwt`, mother's weight at delivery in pounds, `gaweeks`, gestational age in weeks, `smoken`, average number of cigarettes smoked per day during pregnancy, and `wtgain`, mother's weight gain during pregnancy in pounds. The P values for the predictors are all less than 0.01, so none of the hypothesized predictors need to be removed from the model.

Plotting residuals against fitted values

```{r}
bw_df |> 
  modelr::add_residuals(fit) |> 
  modelr::add_predictions(fit) |> 
  ggplot(aes(x = resid, y = pred)) +
  geom_point(alpha = 0.5)
```

The residuals plot shows the majority of residual values being clustered around 0, with the average predicted birthweight sitting at around 3250 grams.

Comparing the model to two others

```{r}
cv_df =
  crossv_mc(bw_df, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
cv_df = cv_df |> 
  mutate(
    model_prop = map(train, \(df) lm(bwt ~ delwt + gaweeks + smoken + wtgain, data = df)),
    model_1 = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model_2 = map(train, \(df) lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = df))) |> 
  mutate(
    rmse_prop = map2_dbl(model_prop, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_1 = map2_dbl(model_1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_2 = map2_dbl(model_2, test, \(mod, df) rmse(model = mod, data = df)))

cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

The plot displays the RMSE value distributions for the three different models. Model 2, the second model offered for comparison (with the interaction terms), has the lowest RMSE values and thus has better predictive performance than the proposed model and the model with only the main effects. The model with the three-way interaction has the best fit.





